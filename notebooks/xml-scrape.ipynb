{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('!', '.')\n",
    "    text = text.replace(':', ',')\n",
    "    text = text.replace('--', ',')\n",
    "    \n",
    "    #reg = \"(?<=[a-zA-Z])-(?=[a-zA-Z]{2,})\"  ## comment this out please! no replacing '-'s for malay\n",
    "    #r = re.compile(reg, re.DOTALL)\n",
    "    #text = r.sub(' ', text)\n",
    "    text = re.sub(r'\\[.+?\\]','',text)\n",
    "    text = re.sub(r'( -| - |- )','',text)\n",
    "    text = re.sub(r'(?<=[a-zA-Z])\\.(?=[a-zA-Z])','. ',text)\n",
    "    text = re.sub(r'(?<=[a-zA-Z])\\?(?=[a-zA-Z])','? ',text)\n",
    "    text = re.sub(r'(?<=[a-zA-Z])\\,(?=[a-zA-Z])',', ',text)\n",
    "#     text = text.replace('-', ',')\n",
    "    text = text.replace(';', '.')    # replace symbols with the most relevant counterparts\n",
    "    text = text.replace(' ,', ',')\n",
    "    text = text.replace('♫', '')\n",
    "    text = text.replace('♪ ♪',',')\n",
    "    text = text.replace('♪','')\n",
    "    text = text.replace('...', '')\n",
    "    text = text.replace(r'.\\s*\\\"', ',')\n",
    "    text = text.replace(r',\\s*\"',', ')\n",
    "    text = text.replace(r'\"', ',')\n",
    "\n",
    "    text = re.sub(r'--\\s?--', '', text) # replace --   -- to ''\n",
    "    text = re.sub(r'\\s+', ' ', text)    # replace all extra whitespaces\n",
    "    \n",
    "    text = re.sub(r',\\s?,', ',', text)  # merge commas separating only whitespace\n",
    "    text = re.sub(r',\\s?\\.', '.', text) # , . -> ,\n",
    "    text = re.sub(r'(?<=[a-zA-Z0-9]),(?=[a-zA-Z0-9])',', ',text) # say,you -> say, you\n",
    "    text = re.sub(r'\\?\\s?\\.', '?', text)# ? . -> ?\n",
    "    text = re.sub(r'\\s+', ' ', text)    # strip all redundant whitespace that could have been caused by preprocessing\n",
    "    \n",
    "    text = re.sub(r'\\s+\\?', '?', text)\n",
    "    text = re.sub(r'\\s+,', ',', text)\n",
    "    text = re.sub(r'\\.[\\s+\\.]+', '. ', text)\n",
    "    text = re.sub(r'\\s+\\.', '.', text)\n",
    "    \n",
    "    return text.strip().lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "dataset_dir = \"./dataset/malay-dataset/local-movies-subtitle\"\n",
    "subtitle_text_list = []\n",
    "file_list = []\n",
    "for dirpath,subdirs,files in os.walk(dataset_dir):\n",
    "    for f in files:\n",
    "        if \"ms\" in f:\n",
    "            file_list.append(os.path.join(dirpath,f))\n",
    "\n",
    "for file in file_list: \n",
    "    subfile = open(file,'rb')\n",
    "    lines = subfile.read()\n",
    "    xml = BeautifulSoup(lines,'lxml-xml')\n",
    "    subtitle_content = xml.find_all('p')\n",
    "    subtitle_text = \"\"\n",
    "    for sub in subtitle_content:\n",
    "        subtitle_text = subtitle_text+\" \"+sub.getText()\n",
    "    subtitle_text = clean_text(subtitle_text[1:])\n",
    "    subtitle_text_list.append(subtitle_text)\n",
    "\n",
    "\n",
    "lines = []\n",
    "with open('./dataset/malay-dataset/dumping-iium.txt','r') as f:\n",
    "    lines = f.readlines()\n",
    "    i = 0\n",
    "    prev = 0\n",
    "    len_sentence = 0\n",
    "    while i < len(lines):\n",
    "        prev = i\n",
    "        while len_sentence <= 512 and i < len(lines):\n",
    "            len_sentence += len(lines[i].split())\n",
    "            i+=1\n",
    "        len_sentence = 0\n",
    "        stri = clean_text(\" \".join(lines[prev:i]))\n",
    "        subtitle_text_list.append(stri)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#subtitle_text_list.extend(lines)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "len(subtitle_text_list)\n",
    "comma = period = question = 0\n",
    "for i in tqdm(subtitle_text_list):\n",
    "    for j in i:\n",
    "        if j == ',':\n",
    "            comma += 1\n",
    "        elif j == '.':\n",
    "            period += 1\n",
    "        elif j == '?':\n",
    "            question+=1\n",
    "\n",
    "word_count = 0\n",
    "for j in tqdm(subtitle_text_list):\n",
    "    for i in j.split():\n",
    "        if len(i) == 1 and i not in [',','?','.','!','>','<','(',')','[',']']:\n",
    "            word_count+=1\n",
    "        elif len(i) > 1:\n",
    "            word_count+=1\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "931d6e47a0ea43c681b8dbc6d83ee867"
      },
      "text/plain": [
       "  0%|          | 0/23642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ca798c6fc014709b5894a4011f72c00"
      },
      "text/plain": [
       "  0%|          | 0/23642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from texttable import Texttable\n",
    "result = Texttable()\n",
    "result.add_rows([['Word count','period','comma','question'],[word_count, period, comma, question]])\n",
    "\n",
    "print(result.draw())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------+---------+--------+----------+\n",
      "| Word count | period  | comma  | question |\n",
      "+============+=========+========+==========+\n",
      "| 12264238   | 1087381 | 623625 | 55978    |\n",
      "+------------+---------+--------+----------+\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "\n",
    "for i in range(len(subtitle_text_list)):\n",
    "    subtitle_text_list[i]+='\\n'\n",
    "with open(\"dataset.txt\",'w') as f:\n",
    "    f.writelines(subtitle_text_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1117472 635745 64486\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('mPunct': venv)"
  },
  "interpreter": {
   "hash": "06104f49c891daee45eafca5ae03f03e0f4b8073189a7d11a82672024b1da1ff"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}