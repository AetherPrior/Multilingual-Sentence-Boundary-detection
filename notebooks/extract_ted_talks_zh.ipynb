{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dev set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_path = \"../dataset/zh-en/\"\n",
    "file_path = data_path + \"IWSLT12.TALK.dev2010.zh-en.zh.xml\" #\"train.tags.en-fr.en\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "xmlp = ET.XMLParser(encoding=\"utf-8\")\n",
    "tree = ET.parse(file_path, parser=xmlp)\n",
    "root = tree.getroot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "for child in root:\n",
    "    print(child.tag, child.attrib)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "srcset {'setid': 'iwslt2012-dev2010', 'srclang': 'chinese'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "docs = []\n",
    "\n",
    "for doc_id in range(len(root[0])):\n",
    "    doc_segs = []\n",
    "    doc = root[0][doc_id]\n",
    "    for seg in doc.iter('seg'):\n",
    "        doc_segs.append(seg.text)\n",
    "    docs.append(doc_segs)\n",
    "\n",
    "print(docs[0])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[' 首先，我要用最快的速度为大家演示  一些新技术的基础研究成果。  正好是一年前，微软收购了我们公司，  而我们为微软带来了这项技术，它就是Seadragon。   ', ' Seadragon是一个软件环境，你可以通过它以近景或远景的方式  浏览浩瀚的可视化数据。   ', ' 我们这里看到的是许多许多GB（千兆字节）级别的数码照片，  对它们可以进行持续并且平滑的放大，  可以通过全景的方式浏览它们，还可以对它们进行重新排列。   ', ' 不管所见到的数据有多少、  图像集有多大以及图像本身有多大，Seadragon都拥有这样的处理能力。   ', ' 以上展示的图片大部分都是由数码相机拍摄的照片，  但这个例子则不同，它是一张来自国会图书馆的扫描图片，  拥有3亿个像素。   ', ' 然而，浏览它并没有什么区别，  因为限制系统性能的唯一因素只是：  你所使用的屏幕的像素数。  Seadragon同时也是一个非常灵活的架构。   ', ' 举个例子，这是一本完整的书，它的数据是非图像的(文本)。   ', ' 这是狄更斯所著的《荒凉山庄》，一列就是一章的内容。   ', ' 我给大家证明一下这真的是文本而非图片，  我们可以这样操作，  大家可以看出这真的是文本，而不是一幅图片。   ', ' 也许这会是一种阅读电子书的方式，   ', ' 但是我可不推荐这么做。   ', ' 接下来是一个更加实际的例子，这是一期《卫报》。   ', ' 每一张大图片是一版开篇，   ', ' 而报纸或者杂志的纸质版本本身就包含了多种比例的图片，  在阅读的时候，读者会得到更好的阅读体验，  从而享受阅读的乐趣。   ', ' 我们在这里做了小小的改动  在这一期《卫报》得角上。   ', ' 我们虚构了一个高分辨率的广告图片——  这比你平常看到的普通广告的分辨率要高很多，  在图片中嵌入了额外的内容。   ', ' 如果你希望看到这辆车的特性，你可以看这里。   ', ' 你还能看到其他的型号，甚至技术规格。   ', ' 这种方式在一定程度上  避免了屏幕实际使用面积的限制。   ', ' 我们希望这个技术能够减少不必要的弹出窗口  以及类似的垃圾信息。   ', ' 显然，对于这项技术的应用，  数字地图也是显而易见的应用之一。   ', ' 对此，我真的不想花费太多的时间进行介绍，  我只想告诉大家我们已经对这个领域做出了自己的贡献。   ', ' 这些只是在NASA的地理空间图片基础上   ', ' 进行叠加处理而得到的美国的道路地图。   ', ' 现在，我们先放下这些，看看其他的。   ', ' 实际上，这项技术已经放到网上了，大家可以自己去体验一下。   ', ' 这个项目叫Photosynth，  它实际上融合了两个不同的技术：   ', ' 一个是Seadragon，  而另一个则是源自华盛顿大学的研究生Noah Snavely  所进行的计算机视觉研究的成果。  这项研究还得到了华盛顿大学Steve Seitz   ', ' 和微软研究院Rick Szeliski的协助。这是一个非常漂亮的合作成果。   ', ' 这个项目在互联网上已经得到应用了，它是基于Seadragon技术构建的。   ', ' 你可以看到，我们轻松地对图片进行多种方式的查看，  从而能够对图片进行细致的剖析  并且拥有多分辨率的浏览体验。   ', ' 不过，这些图片在三维空间的排列事实上是非常有意义的。   ', ' 计算机视觉算法将这些图片联系到一起，  那么这些图片就能够将真实空间呈现出来了，  而我们正是在这个空间里拍下了上述的照片——这些照片都是在  加拿大落基山脉的格拉西湖（Grassi Lakes）附近拍下的——（所有照片）都是在这里拍下的。  因此你可以看到这里的元素是稳定的幻灯放映或者全景成像，  而这些内容在空间上都是关联的。   ', ' 我不确定我们是否有时间来展示更多的环境全景。   ', ' 有很多例子比这个的空间感还要强。   ', ' 下面让我们来看一下去年夏天，  我们利用Noah早期的数据库之一  所Photosynth的初期模型的建立。  我认为  这可谓是我们这项技术的最抢眼之处。  这项技术不单单像我们在  网站上展示得那么简单明了。   ', ' 主要因为我们制作网站时，要顾及到很多法律问题。   ', ' 这里是利用Flickr网站上  的图像重建的巴黎圣母院。  你所要做的只是在Flickr网站上输入“巴黎圣母院”  然后便能看到很多图片，包括留影的游人等等。  所有这些橘黄颜色的锥形都代表了一张  用来建立模型的图片。   ', ' 这些全部是来自Flickr的图片，  被这样在空间里被串联起来。   ', ' 接着，我们便可如此自如的进行浏览。   ', ' 说实话，我从来没想过我会最后来为微软工作   ', ' 受到这样欢迎，真挺令人高兴的。   ', ' 我想你们可以看出  这些图片原自很多不同的相机：  从手机摄像头到专业单反。  如此大量的不同质量的照片，全被在这个环境下  拼合在了一起   ', ' 让我来找些比较诡异的图片。   ', ' 看，不少照片包含了游客的大头照等等。   ', ' 我记得这儿应该有  一个系列的照片 - 啊，在这儿。   ', ' 这个是巴黎圣母院的海报。   ', ' 我们可以钻到海报里  去看整个重建的环境。   ', ' 这里的重点呢便是我们可以  有效地利用网络社区。我们可以从每个人那里得到数据  将每个人对不同环境  的记忆收集在一起，  共建成模型。   ', ' 当所有这些图片交织在一起时，  所衍生出的  要远远超过单单收集起全部。   ', ' 这个模型所衍生出的，是整个地球。   ', ' 这如同是Stephen Lawler的《虚拟地球》的长尾市场。（Stephen Lawler 微软Virtual Earth项目主管）（见Long tail 长尾市场 TED: Chris Anderson ）   ', ' 这类模型，会随着人们的  使用而不断变的复杂，  变得更加有价值。   ', ' 用户的照片，会被大家  注上标签。   ', ' 如果有人愿意为所有这些圣母院里的圣贤注上标签，  表明他们是谁，那我们的圣母院照片便会  一下子丰富起来，  然后呢，我们便能以这张照片为起点，进入这个空间，  这个由很多人的照片所搭建的虚拟世界，  从而得到一种跨越模型，  跨越用户的交互体验。   ', ' 当然了，这一切所带来另外一个宝贵产物便是  一个非常丰富的模型 - 充斥  这地球每个角落里有趣的景观。这些景观不再  局限于航空和卫星图片，  而是实实在在的人们按下快门一刻所收藏的记忆的集合。   ', ' 非常感谢！   ', ' 如果我理解正确的话，你们的这个软件将能够  在未来的几年内  将来自全球的图片  接合在一起？   ', ' 是的。这个软件的真正意义便是去探索。   ', ' 它在图片间构建起超链接。   ', ' 这个接合的过程  完全是基于图片的内容。   ', ' 更令人兴奋的  在于图片所包含的大量文字语义信息。   ', ' 比如，你在网上所以一张图片，  键入关键词后，网页上的文字内容  将包含大量与这个图片相关的信息。   ', ' 现在，假设这些图片全都与你的图片相连，那将会怎样？   ', ' 那时，所以这些语义信息的相互链接  以及内容量将是  巨大的。这将是非常典型的网络效应。   ', ' Blaise，太难以置信了。祝贺你们！   ', ' 非常感谢各位！   ']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dev_texts = [re.sub(r'\\s+', ' ', ''.join(d)).strip() for d in docs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "with open(data_path + 'dev_texts_zh.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in dev_texts:\n",
    "        f.write(text + '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test set 2010"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "file_path = data_path + \"IWSLT12.TALK.tst2010.zh-en.zh.xml\"\n",
    "\n",
    "xmlp = ET.XMLParser(encoding=\"utf-8\")\n",
    "tree = ET.parse(file_path, parser=xmlp)\n",
    "root = tree.getroot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "docs = []\n",
    "\n",
    "for doc_id in range(len(root[0])):\n",
    "    doc_segs = []\n",
    "    doc = root[0][doc_id]\n",
    "    for seg in doc.iter('seg'):\n",
    "        doc_segs.append(seg.text)\n",
    "    docs.append(doc_segs)\n",
    "\n",
    "test_texts_2012 = [re.sub(r'\\s+', ' ', ''.join(d)).strip() for d in docs]\n",
    "\n",
    "with open(data_path + 'test_texts_zh.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in test_texts_2012:\n",
    "        f.write(text + '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "file_path = data_path + \"train.tags.zh-en.zh\"\n",
    "\n",
    "\"\"\" Wrap original file to make it processable with defualt python parser\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<mteval>\n",
    "...\n",
    "</mteval>\n",
    "\"\"\"\n",
    "xmlp = ET.XMLParser(encoding=\"utf-8\")\n",
    "tree = ET.parse(file_path, parser=xmlp)\n",
    "root = tree.getroot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "docs = []\n",
    "\n",
    "for doc in root.iter('transcript'):\n",
    "    docs.append(doc.text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_texts = [re.sub(r'\\s+', ' ', d.replace('\\n', ' ')).strip() for d in docs]\n",
    "\n",
    "\n",
    "with open(data_path + 'train_texts_zh.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in train_texts:\n",
    "        f.write(text + '\\n')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('mPunct': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "06104f49c891daee45eafca5ae03f03e0f4b8073189a7d11a82672024b1da1ff"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}