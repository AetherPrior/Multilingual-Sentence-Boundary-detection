{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"evaluate_test.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naArRkl_4JzP","executionInfo":{"status":"ok","timestamp":1631514787173,"user_tz":-330,"elapsed":1423,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}},"outputId":"6d802c81-0148-4c56-d2b8-ece54f58b25d"},"source":["%cd /content/drive/MyDrive/SUD_PROJECT/neural-punctuator/src"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SUD_PROJECT/neural-punctuator/src\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47lgi2xM21rd","executionInfo":{"status":"ok","timestamp":1631514782783,"user_tz":-330,"elapsed":28701,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}},"outputId":"4b79a845-121c-4d87-bed5-64f93c3c7893"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"rx2BMZKf3Q4y","executionInfo":{"status":"ok","timestamp":1631514754092,"user_tz":-330,"elapsed":3471,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}}},"source":["\n","import os\n","from glob import glob\n","import torch\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pickle\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqAfEBDq3Q42","executionInfo":{"status":"ok","timestamp":1631514857952,"user_tz":-330,"elapsed":351,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}}},"source":["data_path = \"/content/drive/MyDrive/SUD_PROJECT/neural-punctuator/models-xlm-roberta-runs/models-xlm-roberta-masked-chinese/\"\n","model_names = [\"xlm-roberta-base\"]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Up7aTse3Q43","executionInfo":{"status":"ok","timestamp":1631514861157,"user_tz":-330,"elapsed":559,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}}},"source":["files = {}\n","for model_name in model_names:\n","    f = sorted(glob(data_path + f\"{model_name}-epoch*.*\"), key=os.path.getmtime)\n","    files[model_name] = f"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsPUROIX3Q44","executionInfo":{"status":"ok","timestamp":1631515634604,"user_tz":-330,"elapsed":280583,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}},"outputId":"deeabf59-559e-4cfa-b267-c0a1f1b945c3"},"source":["def load_scores(model_path):\n","    checkpoint = torch.load(model_path)\n","    return checkpoint['metrics']\n","\n","def get_strict_f_score(report):\n","    return sum(float(report['cls_report'][output]['f1-score']) for output in ('period', 'question', 'comma')) / 3\n","\n","\n","metrics = {}\n","for model_name in model_names:\n","    m = []\n","    for file in tqdm(files[model_name]):\n","        m.append(load_scores(file))\n","    metrics[model_name] = m\n","    \n","with open('reports/metrics.pkl', 'wb') as f:\n","    pickle.dump(metrics, f)\n","    \n","with open('reports/metrics.pkl', 'rb') as f:\n","    metrics = pickle.load(f)\n","    \n","for _, m in metrics.items():\n","    for epoch in m:\n","        epoch['strict_f_score'] = get_strict_f_score(epoch)\n","\n","def best_epoch_by_f_score(metrics):\n","    best_score = metrics[0]['strict_f_score']\n","    best_epoch = 0\n","    for i, m in enumerate(metrics):\n","        if m['strict_f_score'] > best_score:\n","            best_score = m['strict_f_score']\n","            best_epoch = i\n","    return best_epoch, best_score\n","\n","def best_epoch_by_loss(metrics):\n","    best_loss = metrics[0]['loss']\n","    best_epoch = 0\n","    for i, m in enumerate(metrics):\n","        if m['loss'] < best_loss:\n","            best_loss = m['loss']\n","            best_epoch = i\n","    return best_epoch, best_loss"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4/4 [04:39<00:00, 69.96s/it]\n"]}]},{"cell_type":"code","metadata":{"id":"oS9LXpXG3Q46","colab":{"base_uri":"https://localhost:8080/","height":543},"executionInfo":{"status":"ok","timestamp":1631514971302,"user_tz":-330,"elapsed":1700,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}},"outputId":"aeca83a5-0201-45cc-cdb2-5115cb67947a"},"source":["plt.style.use('seaborn-whitegrid')\n","# plt.title('Valid loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","for model_name, m in metrics.items():\n","    loss = [float(epoch['loss']) for epoch in m ]\n","    plt.plot(np.arange(len(loss))+1, loss, '--d')\n","plt.legend(model_names)\n","plt.savefig('imgs/valid_loss.pdf')\n","plt.show()\n","\n","plt.style.use('seaborn-whitegrid')\n","# plt.title('Valid F1-score')\n","plt.ylabel('Macro $F_1$ score')\n","plt.xlabel('Epoch')\n","for model_name, m in metrics.items():\n","    f_score = [float(epoch['strict_f_score']) for epoch in m ]\n","    plt.plot(np.arange(len(loss))+1, f_score, '--d')\n","plt.legend(model_names)\n","plt.savefig('imgs/valid_f1_score.pdf')\n","plt.show()"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LidJO9X83Q47","executionInfo":{"status":"ok","timestamp":1631515035188,"user_tz":-330,"elapsed":11159,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}},"outputId":"304f0232-6c87-4fd6-aeaf-db811291181a"},"source":["!pip install dotmap\n","!pip install transformers\n","!pip install -U PyYAML\n","from neural_punctuator.utils.data import get_config_from_yaml\n","from neural_punctuator.models.BertPunctuator import BertPunctuator\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from neural_punctuator.data.dataloader import BertDataset, collate, get_data_loaders, get_datasets_metrics\n","from neural_punctuator.models.BertPunctuator import BertPunctuator\n","from torch.optim import AdamW\n","from torch import nn\n","\n","from neural_punctuator.utils.io import save, load\n","from neural_punctuator.utils.metrics import get_total_grad_norm, get_eval_metrics\n","import numpy as np\n","import pickle\n","\n","from torch.utils.data import Dataset, DataLoader\n","from itertools import product"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dotmap in /usr/local/lib/python3.7/dist-packages (1.3.24)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.16)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"]}]},{"cell_type":"code","metadata":{"id":"CYH36JDQ3Q49","executionInfo":{"status":"ok","timestamp":1631515803141,"user_tz":-330,"elapsed":343,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}}},"source":["def combine(pred_num, preds):\n","    step_num = 512 // pred_num\n","    multi_preds = [preds[i::pred_num].reshape(-1, preds.shape[-1]) for i in range(pred_num)]\n","    for i in range(pred_num):\n","        start_idx = (pred_num - i - 1) * step_num\n","        end_idx = start_idx + (preds.shape[0] - (pred_num-1)*2) * step_num\n","        multi_preds[i] = multi_preds[i][start_idx:end_idx]\n","\n","    multi_preds = np.stack(multi_preds)\n","    multi_preds = np.log(np.exp(multi_preds).mean(0))\n","    return multi_preds\n","\n","def evaluate_multiple_predictions(model_name, model_type, predict_step, device, dataset_type):\n","    if model_type == 'by_f_score':\n","        epoch, _ = best_epoch_by_f_score(metrics[model_name])\n","    elif model_type == 'by_loss':\n","        epoch, _ = best_epoch_by_loss(metrics[model_name])\n","    else:\n","        raise ValueError(\"Model type not valid, options: by_f_score/by_loss\")\n","        \n","    print(model_name, model_type, \"Epoch: \", epoch+1)\n","\n","    config = get_config_from_yaml(f'neural_punctuator/configs/config-{model_name}.yaml')\n","    config.trainer.load_model = f\"{model_name}-epoch-{epoch + 1}.pth\"\n","\n","    config.model.predict_step = predict_step\n","    config.predict.batch_size = 128\n","\n","    model = BertPunctuator(config)\n","    model.to(device)\n","\n","    load(model, None, config)\n","\n","    test_dataset = BertDataset(dataset_type, config)\n","\n","    test_loader = DataLoader(test_dataset, batch_size=config.predict.batch_size, collate_fn=collate)\n","\n","    model.eval()\n","    all_test_preds = []\n","\n","    for data in tqdm(test_loader):\n","        text, targets = data\n","        with torch.no_grad():\n","            preds, _ = model(text.to(device))\n","\n","        all_test_preds.append(preds.detach().cpu().numpy())\n","\n","    all_test_target = test_dataset.targets[512:-512]\n","    all_test_preds = np.concatenate(all_test_preds)\n","    pred_num = config.model.seq_len // config.model.predict_step\n","\n","    ps = combine(pred_num, all_test_preds)\n","    _targets = np.array(all_test_target[:ps.shape[0]])\n","\n","    ps = ps[_targets != -1]\n","    _targets = _targets[_targets != -1]\n","\n","    report = get_eval_metrics(_targets, ps, config)\n","    return report"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"lutHuhZh3Q4-","executionInfo":{"status":"ok","timestamp":1631515087632,"user_tz":-330,"elapsed":319,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}}},"source":["class BertDataset(Dataset):\n","    def __init__(self, prefix, config, is_train=False):\n","\n","        self.config = config\n","        self.is_train = is_train\n","\n","        with open(self.config.data.data_path + prefix + \"_data.pkl\", 'rb') as f:\n","            texts, targets, _,_,_,_ = pickle.load(f)\n","            self.encoded_texts = 512 * [0] + [word for t in texts for word in t] + 512 * [0]  # Add padding to both ends\n","            self.targets = 512 * [-1] + [t for ts in targets for t in ts] + 512 * [-1]\n","\n","    def __getitem__(self, idx):\n","        if idx == 164:\n","            pass\n","        start_idx = (1+idx) * self.config.model.predict_step\n","        end_idx = start_idx + self.config.model.seq_len\n","        return torch.LongTensor(self.encoded_texts[start_idx: end_idx]),\\\n","               torch.LongTensor(self.targets[start_idx: end_idx])\n","\n","    def __len__(self):\n","        return int(np.ceil((len(self.encoded_texts)-1024)//self.config.model.predict_step))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wdFfC3PF3Q4_","executionInfo":{"status":"error","timestamp":1631516326229,"user_tz":-330,"elapsed":518583,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}},"outputId":"ece1a738-9ee9-4e81-91d9-a244bf13cfbd"},"source":["device = torch.device('cuda:0')\n","torch.cuda.set_device(device)\n","\n","# pred_num_for_tokens = {\n","# #     (\"albert-base-v1\", \"by_loss\"): 32,\n","# #     (\"albert-base-v1\", \"by_f_score\"): 32,\n","# #     (\"bert-base-cased\", \"by_loss\"): 32,\n","# #     (\"bert-base-cased\", \"by_f_score\"): 32,\n","# #     (\"bert-base-uncased\", \"by_loss\"): 32,\n","# #     (\"bert-base-uncased\", \"by_f_score\"): 32,2,\n","# }\n","\n","# model_type = 'by_loss'\n","\n","reports = {}\n","for model_name, model_type in product(model_names, ('by_loss', 'by_f_score')):\n","    pred_num_for_token = 1\n","    while pred_num_for_token <= 64:\n","        predict_step = 512 // pred_num_for_token\n","        report = evaluate_multiple_predictions(model_name, model_type, predict_step, device, \"valid\")\n","        print(model_name, model_type, pred_num_for_token, get_strict_f_score(report))\n","        reports[(model_name, model_type, pred_num_for_token)] = report\n","        pred_num_for_token *=2"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["xlm-roberta-base by_loss Epoch:  4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1/1 [00:05<00:00,  5.32s/it]"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       empty      0.999     0.954     0.976     35615\n","      period      0.366     0.948     0.529       385\n","    question      0.842     0.870     0.856        92\n","       comma      0.496     0.926     0.646      1133\n","\n","    accuracy                          0.953     37225\n","   macro avg      0.676     0.924     0.752     37225\n","weighted avg      0.977     0.953     0.961     37225\n","\n","2021-09-13 06:51:32,470 INFO      Macro precision is: 0.675888065883863\n","2021-09-13 06:51:32,483 INFO      Macro recall is 0.9243784833391377\n","2021-09-13 06:51:32,495 INFO      Macro f-score is 0.7515602226951587\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["xlm-roberta-base by_loss 1 0.6767841096647255\n","xlm-roberta-base by_loss Epoch:  4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 2/2 [00:10<00:00,  5.05s/it]"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       empty      0.999     0.955     0.976     35365\n","      period      0.378     0.953     0.541       385\n","    question      0.798     0.859     0.827        92\n","       comma      0.503     0.939     0.655      1129\n","\n","    accuracy                          0.954     36971\n","   macro avg      0.669     0.926     0.750     36971\n","weighted avg      0.977     0.954     0.962     36971\n","\n","2021-09-13 06:53:14,040 INFO      Macro precision is: 0.6693179687764801\n","2021-09-13 06:53:14,054 INFO      Macro recall is 0.9263676989964045\n","2021-09-13 06:53:14,067 INFO      Macro f-score is 0.7498053929218829\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["xlm-roberta-base by_loss 2 0.6742831039563834\n","xlm-roberta-base by_loss Epoch:  4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 3/3 [00:20<00:00,  6.81s/it]"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       empty      0.999     0.955     0.977     35239\n","      period      0.379     0.951     0.542       385\n","    question      0.833     0.870     0.851        92\n","       comma      0.509     0.942     0.661      1127\n","\n","    accuracy                          0.955     36843\n","   macro avg      0.680     0.929     0.758     36843\n","weighted avg      0.977     0.955     0.962     36843\n","\n","2021-09-13 06:54:26,948 INFO      Macro precision is: 0.6801142459121163\n","2021-09-13 06:54:26,960 INFO      Macro recall is 0.9294895090630652\n","2021-09-13 06:54:26,972 INFO      Macro f-score is 0.7576929541874271\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["xlm-roberta-base by_loss 4 0.6846464133966202\n","xlm-roberta-base by_loss Epoch:  4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 5/5 [00:40<00:00,  8.06s/it]"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       empty      0.999     0.955     0.977     35175\n","      period      0.378     0.951     0.541       385\n","    question      0.830     0.848     0.839        92\n","       comma      0.508     0.942     0.660      1127\n","\n","    accuracy                          0.955     36779\n","   macro avg      0.679     0.924     0.754     36779\n","weighted avg      0.977     0.955     0.962     36779\n","\n","2021-09-13 06:55:29,745 INFO      Macro precision is: 0.6789629363384979\n","2021-09-13 06:55:29,758 INFO      Macro recall is 0.9240202331891402\n","2021-09-13 06:55:29,770 INFO      Macro f-score is 0.7543307737516733\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["xlm-roberta-base by_loss 8 0.6801925189855268\n","xlm-roberta-base by_loss Epoch:  4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 10/10 [01:20<00:00,  8.03s/it]\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       empty      0.999     0.955     0.977     35111\n","      period      0.380     0.953     0.544       385\n","    question      0.830     0.848     0.839        92\n","       comma      0.510     0.943     0.662      1127\n","\n","    accuracy                          0.955     36715\n","   macro avg      0.680     0.925     0.755     36715\n","weighted avg      0.977     0.955     0.962     36715\n","\n","2021-09-13 06:57:15,625 INFO      Macro precision is: 0.6798575555318924\n","2021-09-13 06:57:15,640 INFO      Macro recall is 0.9249351157195109\n","2021-09-13 06:57:15,652 INFO      Macro f-score is 0.755344285510807\n","xlm-roberta-base by_loss 16 0.6815041385639096\n","xlm-roberta-base by_loss Epoch:  4\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"," 42%|████▏     | 8/19 [01:18<01:47,  9.77s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-d928795e9f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mpred_num_for_token\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpredict_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mpred_num_for_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_multiple_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_num_for_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_strict_f_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mreports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_num_for_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-e5de10d0ea71>\u001b[0m in \u001b[0;36mevaluate_multiple_predictions\u001b[0;34m(model_name, model_type, predict_step, device, dataset_type)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mall_test_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mall_test_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"-RlTpC403Q5B"},"source":["with open('reports/valid_english.pkl', 'wb') as f:\n","    pickle.dump(reports, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKC55EQg3Q5B","colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"status":"error","timestamp":1631516350656,"user_tz":-330,"elapsed":344,"user":{"displayName":"Abhinav Rao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09936798814744565178"}},"outputId":"4472ed96-9148-4969-c462-09dd4ce6cadb"},"source":["best_pred_num_for_tokens = {}\n","\n","for model_name, model_type in product(model_names, ('by_loss', 'by_f_score')):\n","    best_score = 0\n","    best_pred_num_for_token = 0\n","    \n","    pred_num_for_token = 1\n","    while pred_num_for_token <= 19:\n","        report = reports[(model_name, model_type, pred_num_for_token)]\n","        score = get_strict_f_score(report)\n","        \n","        if score > best_score:\n","            best_score = score\n","            best_pred_num_for_token = pred_num_for_token\n","        pred_num_for_token *=2\n","        \n","    best_pred_num_for_tokens[(model_name, model_type)] = (best_score, best_pred_num_for_token)\n","best_pred_num_for_tokens"],"execution_count":24,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-7f5e52064115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred_num_for_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mpred_num_for_token\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_num_for_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_strict_f_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: ('xlm-roberta-base', 'by_f_score', 1)"]}]},{"cell_type":"code","metadata":{"id":"Ojd4uQWl3Q5B"},"source":["test_reports = []\n","\n","for (model_name, model_type), (_, pred_num_for_token) in best_pred_num_for_tokens.items():\n","    if model_type == 'by_f_score':\n","        epoch, _ = best_epoch_by_f_score(metrics[model_name])\n","    elif model_type == 'by_loss':\n","        epoch, _ = best_epoch_by_loss(metrics[model_name])\n","    else:\n","        raise ValueError(\"Model type not valid, options: by_f_score/by_loss\")\n","        \n","    predict_step = 512 // pred_num_for_token\n","    report = evaluate_multiple_predictions(model_name, model_type, predict_step, device, \"test\")\n","    print(model_name, model_type, pred_num_for_token, get_strict_f_score(report))\n","    #test_reports.append((model_name, model_type, pred_num_for_token, epoch, get_strict_f_score(report), report))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ak7_MAb93Q5C"},"source":["with open('reports/test_english.pkl', 'wb') as f:\n","    pickle.dump(test_reports, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2tgERAA3Q5C"},"source":["test_reports"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"kkbqTUuT3Q5D"},"source":["for model_name, model_type, pred_num_for_token, epoch, strict_f_score, report in test_reports:\n","    print(\"Model name\\t\\tModel type\\t# preds/token\\tEpoch\\tF non-empty\\tF\")\n","    \n","    print(f\"{model_name:20}\\t{model_type:10}\\t\"+\n","          f\"{pred_num_for_token}\\t\\t{epoch}\\t{strict_f_score*100:.1f}\\t\\t{report['f_score']*100:.1f}\")\n","    \n","    print(\" \"*18 + \"\\t\".join(('P', 'R', 'F')))\n","    for punc_type in ('comma', 'period', 'question'):\n","        print(f\"{punc_type:15}\", end=\"\")\n","        for metric_type in ('precision', 'recall', 'f1-score'):        \n","            print(f\"\\t{report['cls_report'][punc_type][metric_type]*100:.1f}\", end=\"\")\n","        print()\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QrMo1rhy3Q5D"},"source":["# Plots for number of preds per token  selection"]},{"cell_type":"code","metadata":{"id":"aJ1LLlxe3Q5D"},"source":["import pickle\n","\n","with open('reports/valid_english.pkl', 'rb') as f:\n","    reports = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MW33uWzW3Q5D"},"source":["scores = {}\n","from itertools import product\n","\n","for model_name, model_type in product(model_names, ('by_loss', 'by_f_score')):\n","    pred_num_for_token = 1\n","    s_ = []\n","    while pred_num_for_token <= 64:\n","        report = reports[(model_name, model_type, pred_num_for_token)]\n","        score = get_strict_f_score(report)\n","        s_.append(score)\n","        \n","        pred_num_for_token *=2\n","        \n","    scores[(model_name, model_type)] = s_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKYr5bs73Q5E"},"source":["for (model_name, model_type), f_scores in scores.items():\n","    print(model_name, model_type)\n","    plt.style.use('seaborn-whitegrid')\n","    # plt.title('Multiple predictions')\n","    plt.ylabel('Macro $F_1$ score')\n","    plt.xlabel('Number of predictions per token')\n","    plt.xticks(np.arange(int(np.log2(64))+1), [str(2**i) for i in range(0, int(np.log2(64))+1)])\n","    plt.plot(f_scores[::-1], '--d')\n","    plt.savefig(f'imgs/valid_multiple_predictions/{model_name}_{model_type}.pdf')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_pl_bV83Q5E"},"source":[""],"execution_count":null,"outputs":[]}]}